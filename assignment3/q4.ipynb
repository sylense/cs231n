{
 "nbformat": 3, 
 "nbformat_minor": 0, 
 "worksheets": [
  {
   "cells": [
    {
     "source": [
      "# Visualizing and Breaking ConvNets\n", 
      "In this exercise we will visualize saliency maps for individual images and we will construct images to fool a trained ConvNet."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# A bit of setup\n", 
      "\n", 
      "import numpy as np\n", 
      "import matplotlib.pyplot as plt\n", 
      "from time import time\n", 
      "\n", 
      "%matplotlib inline\n", 
      "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n", 
      "plt.rcParams['image.interpolation'] = 'nearest'\n", 
      "plt.rcParams['image.cmap'] = 'gray'\n", 
      "\n", 
      "# for auto-reloading extenrnal modules\n", 
      "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n", 
      "%load_ext autoreload\n", 
      "%autoreload 2"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Load the data and pretrained model\n", 
      "You should have already downloaded the TinyImageNet-100-A dataset and the pretrained models."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# Load the TinyImageNet-100-A dataset and a pretrained model\n", 
      "\n", 
      "from cs231n.data_utils import load_tiny_imagenet, load_models\n", 
      "\n", 
      "tiny_imagenet_a = 'cs231n/datasets/tiny-imagenet-100-A'\n", 
      "        \n", 
      "class_names, X_train, y_train, X_val, y_val, X_test, y_test = load_tiny_imagenet(tiny_imagenet_a)\n", 
      "\n", 
      "# Zero-mean the data\n", 
      "mean_img = np.mean(X_train, axis=0)\n", 
      "X_train -= mean_img\n", 
      "X_val -= mean_img\n", 
      "X_test -= mean_img\n", 
      "\n", 
      "# Load a pretrained model; it is a five layer convnet.\n", 
      "models_dir = 'cs231n/datasets/tiny-100-A-pretrained'\n", 
      "model = load_models(models_dir)['model1']"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Compute predictions on validation set\n", 
      "For the experiments in this exercise it will be useful to have access to the predictions of the trained ConvNet on the TinyImageNet-100-A validation set."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "from cs231n.classifiers.convnet import five_layer_convnet\n", 
      "\n", 
      "# Array of shape (X_val.shape[0],) storing predictions on the validation set.\n", 
      "# y_val_pred[i] = c indicates that the model predicts that X_val[i] has label c.\n", 
      "y_val_pred = None\n", 
      "\n", 
      "################################################################################\n", 
      "# TODO: Use the pretrained model stored in model to compute predictions on the #\n", 
      "# validation set. Store the results in y_val_pred.                             #\n", 
      "#                                                                              #\n", 
      "# HINT: As in the previous exercises, you will want to break the validation    #\n", 
      "# set into batches.                                                            #\n", 
      "################################################################################\n", 
      "pass\n", 
      "################################################################################\n", 
      "#                              END OF YOUR CODE                                #\n", 
      "################################################################################\n", 
      "\n", 
      "correct_indices, = np.nonzero(y_val_pred == y_val)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Visualize Saliency Maps\n", 
      "In a recent paper [1], it was suggested that you can understand which part of an image is important for classification by visualizing the gradient of the correct class score with respect to the input image. This was covered in lecture on 2/2/2015 under the section \"Visualize the data gradient\". Recall that if a region of the image has a high data gradient, then this indicates that the output of the ConvNet is sensitive to perturbations in that region of the input image.\n", 
      "\n", 
      "We will do something similar, instead visualizing the gradient of the data loss with respect to the input image; this gives similar results and is cleaner to implement using our codebase.\n", 
      "\n", 
      "First, open the file `cs231n/classifiers/convnet.py` and modify the `five_layer_net` function to return the gradient of the loss with respect to the input when the `compute_dX` flag is true.\n", 
      "\n", 
      "Once you have done so, complete the implementation in the following cell to allow you to visualize image-specific class saliency maps for images in the TinyImageNet-100-A validation set.\n", 
      "\n", 
      "[1] K. Simonyan, A. Vedaldi, A. Zisserman , \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", ICLR Workshop 2014"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "def show_image(img, rescale=False, add_mean=True):\n", 
      "    \"\"\"\n", 
      "    Utility to show an image. In our ConvNets, images are 3D slices of 4D\n", 
      "    volumes; to visualize them we need to squeeze out the extra dimension,\n", 
      "    flip the axes so that channels are last, add the mean image, convert to\n", 
      "    uint8, and possibly rescale to be between 0 and 255. To make figures\n", 
      "    prettier we also need to suppress the axis labels after imshow.\n", 
      "    \n", 
      "    Input:\n", 
      "    - img: (1, C, H, W) or (C, H, W) or (1, H, W) or (H, W) giving\n", 
      "      pixel data for an image.\n", 
      "    - rescale: If true rescale the data to fit between 0 and 255\n", 
      "    - add_mean: If true add the training data mean image\n", 
      "    \"\"\"\n", 
      "    img = img.copy()\n", 
      "    if add_mean:\n", 
      "        img += mean_img\n", 
      "    img = img.squeeze()\n", 
      "    if img.ndim == 3:\n", 
      "        img = img.transpose(1, 2, 0)\n", 
      "    if rescale:\n", 
      "        low, high = np.min(img), np.max(img)\n", 
      "        img = 255.0 * (img - low) / (high - low)\n", 
      "    plt.imshow(img.astype('uint8'))\n", 
      "    plt.gca().axis('off')\n", 
      "\n", 
      "# The number of example images to show. You can change this.\n", 
      "num_examples = 6\n", 
      "\n", 
      "# The label of the class to visualize. You can change this.\n", 
      "class_idx = 22 # goldfish\n", 
      "\n", 
      "# An array of shape (num_examples,) containing the indices of validation set\n", 
      "# images for which saliency maps will be visualized. We wil visualize several\n", 
      "# examples of images from the validation set whose label is class_idx and which\n", 
      "# are correctly classified using the pretrained ConvNet. In other words, if\n", 
      "# example_idxs[i] = j then we should have y_val[j] = class_idx and the pretrained\n", 
      "# ConvNet should correctly classify X_val[j].\n", 
      "example_idxs = None\n", 
      "\n", 
      "################################################################################\n", 
      "# TODO: Choose several examples from the validation set whose correct label is #\n", 
      "# class_idx and which are correctly classified by the pretrained ConvNet.      #\n", 
      "# Store the results in the example_idxs variable.                              #\n", 
      "################################################################################\n", 
      "pass\n", 
      "################################################################################\n", 
      "#                              END OF YOUR CODE                                #\n", 
      "################################################################################\n", 
      "\n", 
      "# Array to store gradients of the loss with respect to your chosen example images.\n", 
      "dX = np.zeros((num_examples, 3, 64, 64))\n", 
      "\n", 
      "################################################################################\n", 
      "# TODO: Compute image gradients for your chosen examples. Store the result in  #\n", 
      "# the dX variable.                                                             #\n", 
      "################################################################################\n", 
      "pass\n", 
      "################################################################################\n", 
      "#                              END OF YOUR CODE                                #\n", 
      "################################################################################\n", 
      "\n", 
      "# Plot the images and their saliency maps.\n", 
      "for i in xrange(num_examples):\n", 
      "    # Visualize the image\n", 
      "    plt.subplot(2, num_examples, i + 1)\n", 
      "    show_image(X_val[example_idxs[i]])\n", 
      "    plt.title(class_names[y_val[example_idxs[i]]][0])\n", 
      "    \n", 
      "    # Saliency map for the ith example image.\n", 
      "    sal = np.zeros((64, 64))\n", 
      "    \n", 
      "    ############################################################################\n", 
      "    # TODO: Compute the saliency map for the ith example image. Use image      #\n", 
      "    # derivatives from dX[i] to compute the saliency map for                   #\n", 
      "    # X_val[example_idxs[i]]. Store the result in the sal variable.            #\n", 
      "    ############################################################################\n", 
      "    pass\n", 
      "    ############################################################################\n", 
      "    #                            END OF YOUR CODE                              #\n", 
      "    ############################################################################\n", 
      "    \n", 
      "    # Visualize its saliency map.\n", 
      "    plt.subplot(2, num_examples, num_examples + i + 1)\n", 
      "    show_image(sal, rescale=True, add_mean=False)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Fooling images for ConvNets\n", 
      "Two other papers [1, 2] discussed in lecture on 2/2 presented the idea of performing optimization over the input images to construct images that \"fool\" a trained ConvNet. This paper showed that given a trained ConvNet, an input image, and a desired label, that we can add a small amount of noise to the input image to force the ConvNet to classify it as having the desired label.\n", 
      "\n", 
      "In this section we will reproduce some of these results.\n", 
      "\n", 
      "Suppose that $L(x, y, m)$ is the data loss under model $m$, where we tell the network that the input $x$ should be classified as having label $y$. Given a starting image $x_0$, a desired label $y$, and a pretrained model $m$, we will create a fooling image $x_f$ by solving the following optimization problem:\n", 
      "\n", 
      "$$x_f = \\arg\\min_x \\left(L(x, y, m) + \\frac\\lambda2 \\|x - x_0\\|^2_2\\right)$$\n", 
      "\n", 
      "The term $\\|x - x_0\\|^2$ is $L_2$ regularization in image space which encourages the fooling image to look similar to the starting image, and the constant $\\lambda$ is the strength of this regularization. We will use gradient descent to perform optimization under this model.\n", 
      "\n", 
      "In the past, when using gradient descent we have stopped after a fixed number of iterations. Here we will use a different stopping criteria. Suppose that $p(x=y \\mid m)$ is the probability that the input $x$ is assigned the label $y$ under the model $m$. We will specify a desired *confidence threshold* $t$ for the fooling image, and we will stop our optimization when we have $p(x_f=y\\mid m) >= t$.\n", 
      "\n", 
      "[1] Szegedy, Christian, et al. \"Intriguing properties of neural networks.\" arXiv preprint, 2013.\n", 
      "<br>\n", 
      "[2] Nguyen, Anh, Jason Yosinski, and Jeff Clune. \"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images.\" arXiv preprint, 2014."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "def make_fooling_image(img, y, model, reg=0.0, step_size=500, confidence=0.5):\n", 
      "    \"\"\"\n", 
      "    Perform optimization in image space to create an image that is similar to img\n", 
      "    but is classified as y by model.\n", 
      "    \n", 
      "    Inputs:\n", 
      "    - img: Array of shape (1, C, H, W) containing (mean-subtracted) pixel data for\n", 
      "      the starting point for the fooling image.\n", 
      "    - y: The desired label; should be a single integer.\n", 
      "    - model: Dictionary mapping parameter names to weights; this is a pretrained\n", 
      "      five_layer_net model.\n", 
      "    - reg: Regularization strength (in image space) for the fooling image. This\n", 
      "      is the parameter lambda in the equation above.\n", 
      "    - step_size: The step size to use for gradient descent.\n", 
      "    - confidence: The desired confidence threshold for the fooling image.\n", 
      "    \"\"\"\n", 
      "    fooling_img = img.copy()\n", 
      "    ################################################################################\n", 
      "    # TODO: Use gradient descent in image space to create a fooling image,         #\n", 
      "    # stopping when the predicted probability for the fooling image is greater     #\n", 
      "    # than the specified confidence threshold.                                     #\n", 
      "    ################################################################################\n", 
      "    pass\n", 
      "    ############################################################################\n", 
      "    #                            END OF YOUR CODE                              #\n", 
      "    ############################################################################\n", 
      "            \n", 
      "    return fooling_img"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Fooling images from correctly classified images\n", 
      "We will choose an image that is correctly classified by the pretrained network and create a fooling image that the network classifies as a goldfish.\n", 
      "\n", 
      "You should experiment with different step sizes, regularizations, confidence thresholds, and target classes"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# Choose a random image that is correctly classified\n", 
      "idx = np.random.choice(np.nonzero(y_val_pred == y_val)[0])\n", 
      "img = X_val[idx:idx+1]\n", 
      "class_idx = 22 # Goldfish\n", 
      "confidence = 0.5\n", 
      "fooling_img = make_fooling_image(img, class_idx, model, step_size=1000, reg=0.00002, confidence=confidence)\n", 
      "\n", 
      "# Check that the fooling image has probability above the threshold.\n", 
      "assert five_layer_convnet(fooling_img, model, return_probs=True)[0, class_idx] >= confidence, \\\n", 
      "       'The ConvNet is not fooled.'\n", 
      "\n", 
      "# Show the original image\n", 
      "plt.subplot(1, 3, 1)\n", 
      "plt.title('Original image (%s)' % class_names[y_val[idx]][0])\n", 
      "show_image(img)\n", 
      "\n", 
      "# Show the difference between the original and fooling image\n", 
      "plt.subplot(1, 3, 2)\n", 
      "plt.title('+distort')\n", 
      "show_image(fooling_img - img, add_mean=False, rescale=True)\n", 
      "\n", 
      "# Show the fooling image\n", 
      "plt.subplot(1, 3, 3)\n", 
      "plt.title('Fooling image (%s)' % class_names[class_idx][0])\n", 
      "show_image(fooling_img, rescale=True)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Fooling image from random noise\n", 
      "Instead of starting from a correctly classified image, we can instead start our optimization from random noise. This will allow us to produce fooling images that do not look like anything to humans.\n", 
      "\n", 
      "You should experiment with the scale of the initial random noise, the step size, the regularization, the confidence threshold, and the target class."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# Generate random noise to start\n", 
      "img = 20 * np.random.randn(1, 3, 64, 64)\n", 
      "class_idx = 22 # Goldfish\n", 
      "fooling_img = make_fooling_image(img, class_idx, model, step_size=500, reg=0.00005, confidence=0.5)\n", 
      "\n", 
      "# Check that the fooling image has probability above the threshold.\n", 
      "assert five_layer_convnet(fooling_img, model, return_probs=True)[0, class_idx] >= confidence, \\\n", 
      "       'The ConvNet is not fooled.'\n", 
      "\n", 
      "# Show the original image\n", 
      "plt.subplot(1, 3, 1)\n", 
      "plt.title('Random original image')\n", 
      "show_image(img)\n", 
      "\n", 
      "# Show the difference between the original and fooling image\n", 
      "plt.subplot(1, 3, 2)\n", 
      "plt.title('+distort')\n", 
      "show_image(fooling_img - img, add_mean=False, rescale=True)\n", 
      "\n", 
      "# Show the fooling image\n", 
      "plt.subplot(1, 3, 3)\n", 
      "plt.title('Fooling image (%s)' % class_names[class_idx][0])\n", 
      "show_image(fooling_img, rescale=True)"
     ], 
     "metadata": {}
    }
   ], 
   "metadata": {}
  }
 ], 
 "metadata": {
  "name": "", 
  "signature": "sha256:ba48a90366503ea6ca3127eae16123dabe0dae7afd0c5d7ebed718366e9a4db4"
 }
}