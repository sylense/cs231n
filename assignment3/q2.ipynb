{
 "nbformat": 3, 
 "nbformat_minor": 0, 
 "worksheets": [
  {
   "cells": [
    {
     "source": [
      "# TinyImageNet and Ensembles\n", 
      "So far, we have only worked with the CIFAR-10 dataset. In this exercise we will introduce the TinyImageNet dataset. You will combine several pretrained models into an ensemble, and show that the ensemble performs better than any individual model."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# A bit of setup\n", 
      "\n", 
      "import numpy as np\n", 
      "import matplotlib.pyplot as plt\n", 
      "from time import time\n", 
      "\n", 
      "%matplotlib inline\n", 
      "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n", 
      "plt.rcParams['image.interpolation'] = 'nearest'\n", 
      "plt.rcParams['image.cmap'] = 'gray'\n", 
      "\n", 
      "# for auto-reloading extenrnal modules\n", 
      "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n", 
      "%load_ext autoreload\n", 
      "%autoreload 2"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Introducing TinyImageNet\n", 
      "\n", 
      "The TinyImageNet dataset is a subset of the ILSVRC-2012 classification dataset. It consists of 200 object classes, and for each object class it provides 500 training images, 50 validation images, and 50 test images. All images have been downsampled to 64x64 pixels. We have provided the labels for all training and validation images, but have withheld the labels for the test images.\n", 
      "\n", 
      "We have further split the full TinyImageNet dataset into two equal pieces, each with 100 object classes. We refer to these datasets as TinyImageNet-100-A and TinyImageNet-100-B.\n", 
      "\n", 
      "To download the data, go into the `cs231n/datasets` directory and run the script `get_tiny_imagenet_splits.sh`. Then run the following code to load the TinyImageNet-100-A dataset into memory.\n", 
      "\n", 
      "NOTE: The full TinyImageNet dataset will take up about 490MB of disk space, and loading the full TinyImageNet-100-A dataset into memory will use about 2.8GB of memory."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "from cs231n.data_utils import load_tiny_imagenet\n", 
      "\n", 
      "tiny_imagenet_a = 'cs231n/datasets/tiny-imagenet-100-A'\n", 
      "        \n", 
      "class_names, X_train, y_train, X_val, y_val, X_test, y_test = load_tiny_imagenet(tiny_imagenet_a)\n", 
      "\n", 
      "# Zero-mean the data\n", 
      "mean_img = np.mean(X_train, axis=0)\n", 
      "X_train -= mean_img\n", 
      "X_val -= mean_img\n", 
      "X_test -= mean_img"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# TinyImageNet-100-A classes\n", 
      "Since ImageNet is based on the WordNet ontology, each class in ImageNet (and TinyImageNet) actually has several different names. For example \"pop bottle\" and \"soda bottle\" are both valid names for the same class. Run the following to see a list of all classes in TinyImageNet-100-A:"
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "for names in class_names:\n", 
      "    print ' '.join('\"%s\"' % name for name in names)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Visualize Examples\n", 
      "Run the following to visualize some example images from random classses in TinyImageNet-100-A. It selects classes and images randomly, so you can run it several times to see different images."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "# Visualize some examples of the training data\n", 
      "classes_to_show = 7\n", 
      "examples_per_class = 5\n", 
      "\n", 
      "class_idxs = np.random.choice(len(class_names), size=classes_to_show, replace=False)\n", 
      "for i, class_idx in enumerate(class_idxs):\n", 
      "    train_idxs, = np.nonzero(y_train == class_idx)\n", 
      "    train_idxs = np.random.choice(train_idxs, size=examples_per_class, replace=False)\n", 
      "    for j, train_idx in enumerate(train_idxs):\n", 
      "        img = X_train[train_idx] + mean_img\n", 
      "        img = img.transpose(1, 2, 0).astype('uint8')\n", 
      "        plt.subplot(examples_per_class, classes_to_show, 1 + i + classes_to_show * j)\n", 
      "        if j == 0:\n", 
      "            plt.title(class_names[class_idx][0])\n", 
      "        plt.imshow(img)\n", 
      "        plt.gca().axis('off')\n", 
      "\n", 
      "plt.show()"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Test human performance\n", 
      "Run the following to test your own classification performance on the TinyImageNet-100-A dataset.\n", 
      "\n", 
      "You can run several times in 'training' mode to get familiar with the task; once you are ready to test yourself, switch the mode to `'val'`.\n", 
      "\n", 
      "You won't be penalized if you don't correctly classify all the images, but you should still try your best."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "mode = 'train'\n", 
      "\n", 
      "name_to_label = {n.lower(): i for i, ns in enumerate(class_names) for n in ns}\n", 
      "\n", 
      "if mode == 'train':\n", 
      "    X, y = X_train, y_train\n", 
      "elif mode == 'val':\n", 
      "    X, y = X_val, y_val\n", 
      "    \n", 
      "num_correct = 0\n", 
      "num_images = 10\n", 
      "for i in xrange(num_images):\n", 
      "    idx = np.random.randint(X.shape[0])\n", 
      "    img = (X[idx] + mean_img).transpose(1, 2, 0).astype('uint8')\n", 
      "    plt.imshow(img)\n", 
      "    plt.gca().axis('off')\n", 
      "    plt.gcf().set_size_inches((2, 2))\n", 
      "    plt.show()\n", 
      "    got_name = False\n", 
      "    while not got_name:\n", 
      "        name = raw_input('Guess the class for the above image (%d / %d) : ' % (i + 1, num_images))\n", 
      "        name = name.lower()\n", 
      "        got_name = name in name_to_label\n", 
      "        if not got_name:\n", 
      "            print 'That is not a valid class name; try again'\n", 
      "    guess = name_to_label[name]\n", 
      "    if guess == y[idx]:\n", 
      "        num_correct += 1\n", 
      "        print 'Correct!'\n", 
      "    else:\n", 
      "        print 'Incorrect; it was actually %r' % class_names[y[idx]]\n", 
      "\n", 
      "acc = float(num_correct) / num_images\n", 
      "print 'You got %d / %d correct for an accuracy of %f' % (num_correct, num_images, acc)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Download pretrained models\n", 
      "We have provided 10 pretrained ConvNets for the TinyImageNet-100-A dataset. Each of these models is a five-layer ConvNet with the architecture\n", 
      "\n", 
      "[conv - relu - pool] x 3 - affine - relu - affine - softmax\n", 
      "\n", 
      "All convolutional layers are 3x3 with stride 1 and all pooling layers are 2x2 with stride 2. The first two convolutional layers have 32 filters each, and the third convolutional layer has 64 filters. The hidden affine layer has 512 neurons. You can run the forward and backward pass for these five layer convnets using the function `five_layer_convnet` in the file `cs231n/classifiers/convnet.py`.\n", 
      "\n", 
      "Each of these models was trained for 25 epochs over the TinyImageNet-100-A training data with a batch size of 50 and with dropout on the hidden affine layer. Each model was trained using slightly different values for the learning rate, regularization, and dropout probability.\n", 
      "\n", 
      "To download the pretrained models, go into the `cs231n/datasets` directory and run the `get_pretrained_models.sh` script. Once you have done so, run the following to load the pretrained models into memory.\n", 
      "\n", 
      "NOTE: The pretrained models will take about 245MB of disk space."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "from cs231n.data_utils import load_models\n", 
      "\n", 
      "models_dir = 'cs231n/datasets/tiny-100-A-pretrained'\n", 
      "\n", 
      "# models is a dictionary mappping model names to models.\n", 
      "# Like the previous assignment, each model is a dictionary mapping parameter\n", 
      "# names to parameter values.\n", 
      "models = load_models(models_dir)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Run models on the validation set\n", 
      "To benchmark the performance of each model on its own, we will use each model to make predictions on the validation set."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "from cs231n.classifiers.convnet import five_layer_convnet\n", 
      "\n", 
      "# Dictionary mapping model names to their predicted class probabilities on the\n", 
      "# validation set. model_to_probs[model_name] is an array of shape (N_val, 100)\n", 
      "# where model_to_probs[model_name][i, j] = p indicates that models[model_name]\n", 
      "# predicts that X_val[i] has class i with probability p.\n", 
      "model_to_probs = {}\n", 
      "\n", 
      "################################################################################\n", 
      "# TODO: Use each model to predict classification probabilities for all images  #\n", 
      "# in the validation set. Store the predicted probabilities in the              #\n", 
      "# model_to_probs dictionary as above. To compute forward passes and compute    #\n", 
      "# probabilities, use the function five_layer_convnet in the file               #\n", 
      "# cs231n/classifiers/convnet.py.                                               #\n", 
      "#                                                                              #\n", 
      "# HINT: Trying to predict on the entire validation set all at once will use a  #\n", 
      "# ton of memory, so you should break the validation set into batches and run   #\n", 
      "# each batch through each model separately.                                    #\n", 
      "################################################################################\n", 
      "pass\n", 
      "################################################################################\n", 
      "#                            END OF YOUR CODE                                  #\n", 
      "################################################################################    \n", 
      "\n", 
      "# Compute and print the accuracy for each model.\n", 
      "for model_name, probs in model_to_probs.iteritems():\n", 
      "    acc = np.mean(np.argmax(probs, axis=1) == y_val)\n", 
      "    print '%s got accuracy %f' % (model_name, acc)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Use a model ensemble\n", 
      "A simple way to implement an ensemble of models is to average the predicted probabilites for each model in the ensemble.\n", 
      "\n", 
      "More concretely, suppose we have models $k$ models $m_1,\\ldots,m_k$ and we want to combine them into an ensemble. If $p(x=y_i \\mid m_j)$ is the probability that the input $x$ is classified as $y_i$ under model $m_j$, then the enemble predicts\n", 
      "\n", 
      "$$p(x=y_i \\mid \\{m_1,\\ldots,m_k\\}) = \\frac1k\\sum_{j=1}^kp(x=y_i\\mid m_j)$$\n", 
      "\n", 
      "In the cell below, implement this simple ensemble method by filling in the `compute_ensemble_preds` function. The ensemble of all 10 models should perform much better than the best individual model."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "def compute_ensemble_preds(probs_list):\n", 
      "    \"\"\"\n", 
      "    Use the predicted class probabilities from different models to implement\n", 
      "    the ensembling method described above.\n", 
      "    \n", 
      "    Inputs:\n", 
      "    - probs_list: A list of numpy arrays, where each gives the predicted class\n", 
      "      probabilities under some model. In other words,\n", 
      "      probs_list[j][i, c] = p means that the jth model in the ensemble thinks\n", 
      "      that the ith data point has class c with probability p.\n", 
      "    \n", 
      "    Returns:\n", 
      "    An array y_pred_ensemble of ensembled predictions, such that\n", 
      "    y_pred_ensemble[i] = c means that ensemble predicts that the ith data point\n", 
      "    is predicted to have class c.\n", 
      "    \"\"\"\n", 
      "    y_pred_ensemble = None\n", 
      "    ############################################################################\n", 
      "    # TODO: Implement this function. Store the ensemble predictions in         #\n", 
      "    # y_pred_ensemble.                                                         #\n", 
      "    ############################################################################\n", 
      "    pass\n", 
      "    ############################################################################\n", 
      "    #                             END OF YOUR CODE                             #\n", 
      "    ############################################################################\n", 
      "    return y_pred_ensemble\n", 
      "    \n", 
      "# Combine all models into an ensemble and make predictions on the validation set.\n", 
      "# This should be significantly better than the best individual model.\n", 
      "print np.mean(compute_ensemble_preds(model_to_probs.values()) == y_val)"
     ], 
     "metadata": {}
    }, 
    {
     "source": [
      "# Ensemble size vs Performance\n", 
      "Using our 10 pretrained models, we can form many different ensembles of different sizes. More precisely, if we have $n$ models and we want to form an ensemble of $k$ models, then there are $\\binom{n}{k}$ possible ensembles that we can form, where\n", 
      "\n", 
      "$$\\binom{n}{k} = \\frac{n!}{(n-k)!k!}$$\n", 
      "\n", 
      "We can use these different possible ensembles to study the effect of ensemble size on ensemble performance.\n", 
      "\n", 
      "In the cell below, compute the validation set accuracy of all possible ensembles of our 10 pretrained models. Produce a scatter plot with \"ensemble size\" on the horizontal axis and \"validation set accuracy\" on the vertical axis. Your plot should have a total of\n", 
      "\n", 
      "$$\\sum_{k=1}^{10} \\binom{10}{k}$$\n", 
      "\n", 
      "points corresponding to all possible ensembles of the 10 pretrained models.\n", 
      "\n", 
      "You should be able to compute the validation set predictions of these ensembles without computing any more forward passes through any of the networks."
     ], 
     "cell_type": "markdown", 
     "metadata": {}
    }, 
    {
     "cell_type": "code", 
     "language": "python", 
     "outputs": [], 
     "collapsed": false, 
     "input": [
      "################################################################################\n", 
      "# TODO: Create a plot comparing ensemble size with ensemble performance as     #\n", 
      "# described above.                                                             #\n", 
      "#                                                                              #\n", 
      "# HINT: Look up the function itertools.combinations.                           #\n", 
      "################################################################################\n", 
      "pass\n", 
      "################################################################################\n", 
      "#                            END OF YOUR CODE                                  #\n", 
      "################################################################################"
     ], 
     "metadata": {}
    }
   ], 
   "metadata": {}
  }
 ], 
 "metadata": {
  "name": "", 
  "signature": "sha256:55ea322a484a1adc0abf37516908384c89770c310daffb5d868a8b060b0b9cba"
 }
}